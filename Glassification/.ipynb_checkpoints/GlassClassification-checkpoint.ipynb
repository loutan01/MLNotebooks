{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your choice clustering Problem\n",
    "\n",
    "* Due Monday March 13\n",
    "* Find a dataset that is suitable for clustering.  Make up a Hypothesis about the dataset that you would like to test.  find one where the data already has a categorical variable so you can do an experiment to see how well a couple different algorithms work for that data.  You will work on performing this experiment and it will be due Monday March 13."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Glassification\n",
    "\n",
    "https://www.kaggle.com/uciml/glass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Attribute Information:\n",
    "\n",
    "Id number: 1 to 214\n",
    "\n",
    "RI: refractive index\n",
    "Na: Sodium (unit measurement: weight percent in corresponding oxide, as are attributes 4-10)\n",
    "\n",
    "Mg: Magnesium\n",
    "\n",
    "Al: Aluminum\n",
    "\n",
    "Si: Silicon\n",
    "\n",
    "K: Potassium\n",
    "\n",
    "Ca: Calcium\n",
    "\n",
    "Ba: Barium\n",
    "\n",
    "Fe: Iron\n",
    "\n",
    "Type of glass: \n",
    "\n",
    "1 building_windows_float_processed\n",
    "\n",
    "2 building_windows_non_float_processed\n",
    "\n",
    "3 vehicle_windows_float_processed\n",
    "\n",
    "4 vehicle_windows_non_float_processed (none in this database)\n",
    "\n",
    "5 containers\n",
    "\n",
    "6 tableware\n",
    "\n",
    "7 headlamps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "class glassSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, variety):\n",
    "        self.variety = variety\n",
    "\n",
    "    def fit(self):\n",
    "        return self\n",
    "\n",
    "    def transform(self,df):\n",
    "        result = df.copy()\n",
    "        result['label'] = result.kind.map(lambda x: 1 if x == self.variety else -1)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        RI     Na    Mg    Al     Si     K    Ca   Ba   Fe  Type\n",
       "0  1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.0  0.0     1\n",
       "1  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.0     1\n",
       "2  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.0     1\n",
       "3  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.0     1\n",
       "4  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.0     1"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glassData = pd.read_csv('glass.csv')\n",
    "glassData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.518365</td>\n",
       "      <td>13.407850</td>\n",
       "      <td>2.684533</td>\n",
       "      <td>1.444907</td>\n",
       "      <td>72.650935</td>\n",
       "      <td>0.497056</td>\n",
       "      <td>8.956963</td>\n",
       "      <td>0.175047</td>\n",
       "      <td>0.057009</td>\n",
       "      <td>2.780374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.003037</td>\n",
       "      <td>0.816604</td>\n",
       "      <td>1.442408</td>\n",
       "      <td>0.499270</td>\n",
       "      <td>0.774546</td>\n",
       "      <td>0.652192</td>\n",
       "      <td>1.423153</td>\n",
       "      <td>0.497219</td>\n",
       "      <td>0.097439</td>\n",
       "      <td>2.103739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.511150</td>\n",
       "      <td>10.730000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>69.810000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.430000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.516523</td>\n",
       "      <td>12.907500</td>\n",
       "      <td>2.115000</td>\n",
       "      <td>1.190000</td>\n",
       "      <td>72.280000</td>\n",
       "      <td>0.122500</td>\n",
       "      <td>8.240000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.517680</td>\n",
       "      <td>13.300000</td>\n",
       "      <td>3.480000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>72.790000</td>\n",
       "      <td>0.555000</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.519157</td>\n",
       "      <td>13.825000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>1.630000</td>\n",
       "      <td>73.087500</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>9.172500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.533930</td>\n",
       "      <td>17.380000</td>\n",
       "      <td>4.490000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>75.410000</td>\n",
       "      <td>6.210000</td>\n",
       "      <td>16.190000</td>\n",
       "      <td>3.150000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               RI          Na          Mg          Al          Si           K  \\\n",
       "count  214.000000  214.000000  214.000000  214.000000  214.000000  214.000000   \n",
       "mean     1.518365   13.407850    2.684533    1.444907   72.650935    0.497056   \n",
       "std      0.003037    0.816604    1.442408    0.499270    0.774546    0.652192   \n",
       "min      1.511150   10.730000    0.000000    0.290000   69.810000    0.000000   \n",
       "25%      1.516523   12.907500    2.115000    1.190000   72.280000    0.122500   \n",
       "50%      1.517680   13.300000    3.480000    1.360000   72.790000    0.555000   \n",
       "75%      1.519157   13.825000    3.600000    1.630000   73.087500    0.610000   \n",
       "max      1.533930   17.380000    4.490000    3.500000   75.410000    6.210000   \n",
       "\n",
       "               Ca          Ba          Fe        Type  \n",
       "count  214.000000  214.000000  214.000000  214.000000  \n",
       "mean     8.956963    0.175047    0.057009    2.780374  \n",
       "std      1.423153    0.497219    0.097439    2.103739  \n",
       "min      5.430000    0.000000    0.000000    1.000000  \n",
       "25%      8.240000    0.000000    0.000000    1.000000  \n",
       "50%      8.600000    0.000000    0.000000    2.000000  \n",
       "75%      9.172500    0.000000    0.100000    3.000000  \n",
       "max     16.190000    3.150000    0.510000    7.000000  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glassData.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Compare and contrast the classification of this data using a perceptron and a random forest. Assess the accuracy of both models, analyzing factors such as which types of glass are easiest to confuse, which kinds of glass are easiest to detect, as well as the time it takes the algorithms to train and learn from the dataset.\n",
    "\n",
    "Conjecture: The perceptron will be more accurate at determining the type of glass than a random forest due to the fact that random forests are more prone to overfitting, and are optimized for non-linear models of data whereas the perceptron is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Type</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>building_windows_float_processed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>building_windows_float_processed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>building_windows_float_processed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>building_windows_float_processed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>building_windows_float_processed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        RI     Na    Mg    Al     Si     K    Ca   Ba   Fe  Type  \\\n",
       "0  1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.0  0.0     1   \n",
       "1  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.0     1   \n",
       "2  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.0     1   \n",
       "3  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.0     1   \n",
       "4  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.0     1   \n",
       "\n",
       "                              Label  \n",
       "0  building_windows_float_processed  \n",
       "1  building_windows_float_processed  \n",
       "2  building_windows_float_processed  \n",
       "3  building_windows_float_processed  \n",
       "4  building_windows_float_processed  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#labeling for funsies\n",
    "d = {1:'building_windows_float_processed' , 2: 'building_windows_non_float_processed', 3: 'vehicle_windows_float_processed', 5: 'containers', 6: 'tableware', 7: 'headlamps'}\n",
    "glassData['Label'] = glassData.Type.map(lambda x : d[x])\n",
    "glassData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "class Perceptron(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, class_map={1:1,2:2,3:3,4:4,5:5,6:6,7:7 }):\n",
    "        super().__init__()\n",
    "        self.w = []\n",
    "        self.statistics_ = []\n",
    "        self.class_map = class_map\n",
    "        self.errorCount = []\n",
    "        self.end = 0\n",
    "\n",
    "    def fit(self, ts, cls):\n",
    "        ts = self.transform(ts)  # add 1.0 as zeroth element to each row.\n",
    "        self.w = np.array([random.random() for x in range(len(ts[0]))])\n",
    "        done = False\n",
    "        count = 0\n",
    "        incorrectCount = 0\n",
    "        best_score = len(ts)\n",
    "        best_w = self.w.copy()\n",
    "\n",
    "        while not done and count < 100000:\n",
    "            count += 1\n",
    "            correct = []\n",
    "            incorrect = []\n",
    "\n",
    "            # first classify all points\n",
    "            for ix,i in enumerate(ts):\n",
    "                if np.sign(np.dot(i,self.w)) == cls[ix]:\n",
    "                    correct.append(ix)\n",
    "                else:\n",
    "                    incorrect.append(ix)\n",
    "                    self.errorCount.append(len(incorrect))\n",
    "                \n",
    "\n",
    "            if len(incorrect) < best_score:\n",
    "                best_score = len(incorrect)\n",
    "                best_w = self.w.copy()\n",
    "                \n",
    "            if len(incorrect) == 0:\n",
    "                print(\"Done!\",self.w)\n",
    "                done = True\n",
    "            else:\n",
    "                p = random.randrange(len(incorrect))\n",
    "                x = ts[incorrect[p]]\n",
    "                self.w = self.w + x*cls[incorrect[p]]\n",
    "        \n",
    "        self.statistics_ = [count, best_score]\n",
    "        self.w = best_w.copy()\n",
    "    \n",
    "        \n",
    "\n",
    "    def transform(self, data):\n",
    "        return np.c_[np.array([1.0]*len(data)),data]\n",
    "\n",
    "    def decision_function(self, tset):\n",
    "        tset = self.transform(tset)\n",
    "        scores = []\n",
    "        for s in tset:\n",
    "            scores.append(np.dot(s, self.w))\n",
    "\n",
    "        return scores\n",
    "\n",
    "    def predict(self, tset):\n",
    "        tset = self.transform(tset)\n",
    "        predictions = []\n",
    "        for s in tset:\n",
    "            predictions.append(self.class_map[np.sign(np.dot(s, self.w))])\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1.51662</td>\n",
       "      <td>12.85</td>\n",
       "      <td>3.51</td>\n",
       "      <td>1.44</td>\n",
       "      <td>73.01</td>\n",
       "      <td>0.68</td>\n",
       "      <td>8.23</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>1.51888</td>\n",
       "      <td>14.99</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1.74</td>\n",
       "      <td>72.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>1.52127</td>\n",
       "      <td>14.32</td>\n",
       "      <td>3.90</td>\n",
       "      <td>0.83</td>\n",
       "      <td>71.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>1.51730</td>\n",
       "      <td>12.35</td>\n",
       "      <td>2.72</td>\n",
       "      <td>1.63</td>\n",
       "      <td>72.87</td>\n",
       "      <td>0.70</td>\n",
       "      <td>9.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          RI     Na    Mg    Al     Si     K    Ca    Ba    Fe\n",
       "142  1.51662  12.85  3.51  1.44  73.01  0.68  8.23  0.06  0.25\n",
       "181  1.51888  14.99  0.78  1.74  72.50  0.00  9.95  0.00  0.00\n",
       "151  1.52127  14.32  3.90  0.83  71.50  0.00  9.49  0.00  0.00\n",
       "101  1.51730  12.35  2.72  1.63  72.87  0.70  9.23  0.00  0.00\n",
       "0    1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.00  0.00"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import (train_test_split, StratifiedKFold, \n",
    "                                     cross_val_score)\n",
    "train, test = train_test_split(glassData, train_size=.8, stratify=glassData.Label)\n",
    "labels = train.Type\n",
    "train = train.drop(['Type', 'Label'], axis=1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ptron = Perceptron()\n",
    "ptron.fit(train.values, labels.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tlabels = test.Type\n",
    "#test = test.drop(['Type', 'Label'], axis = 1) \n",
    "preds = ptron.predict(test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14,  0,  0,  0,  0,  0],\n",
       "       [15,  0,  0,  0,  0,  0],\n",
       "       [ 3,  0,  0,  0,  0,  0],\n",
       "       [ 3,  0,  0,  0,  0,  0],\n",
       "       [ 2,  0,  0,  0,  0,  0],\n",
       "       [ 6,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(tlabels.values, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_val\n",
    "comparison = random.randint(1,7)\n",
    "while unique_val == comparison:\n",
    "    comparison = random.randint(1,7)\n",
    "print('val:',d[unique_val] 'comp:', d[comparison])\n",
    "train1 = np.array([x for ix, x in enumerate(train) if labels[ix] == unique_val or labels[ix] == comparison], ndmin=2)\n",
    "map1 = {unique_val:-1, comparison:1}\n",
    "\n",
    "labs1 = [x for x in labels if x == unique_val or x == comparison]\n",
    "labs1 = [map1[x] for x in labs1]\n",
    "\n",
    "p1 = Perceptron(class_map={-1:unique_val, 1:comparison})\n",
    "p1.fit(train1, labs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#attempt at a generalized multiclassifier\n",
    "class PerceptronMultiClassifier(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.ptrons = []\n",
    "\n",
    "    def fit(self, train, labels):\n",
    "        num_classes = np.unique(labels)\n",
    "\n",
    "        for unique_val in num_classes:\n",
    "             \n",
    "            comparison = random.randint(1,len(num_classes)+1)\n",
    "            \n",
    "            while unique_val == comparison or comparison == 4:\n",
    "                comparison = random.randint(1,(len(num_classes)+1))\n",
    "            \n",
    "            print('val:', unique_val, 'comp:', comparison)\n",
    "\n",
    "            \n",
    "            train1 = np.array([x for ix, x in enumerate(train) if labels[ix] == unique_val or labels[ix] == comparison], ndmin=2)\n",
    "            map1 = {unique_val:-1, comparison:1}\n",
    "\n",
    "            labs1 = [x for x in labels if x == unique_val or x == comparison]\n",
    "            labs1 = [map1[x] for x in labs1]\n",
    "\n",
    "            p1 = Perceptron(class_map={-1:unique_val, 1:comparison})\n",
    "            p1.fit(train1, labs1)\n",
    "            \n",
    "            self.ptrons.append(p1)\n",
    "        \n",
    "    def predict(self, tset):\n",
    "        predictions = []\n",
    "        for perceptron in self.ptrons:\n",
    "            predictions.append(perceptron.predict(tset))\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(glassData, train_size=.8, stratify=glassData.Type)\n",
    "y = train.Type\n",
    "train = train.drop(['Type', 'Label'], axis=1)\n",
    "z = test.Type\n",
    "test = test.drop(['Type','Label'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val: 1 comp: 7\n",
      "val: 2 comp: 3\n",
      "val: 3 comp: 2\n",
      "val: 5 comp: 7\n",
      "Done! [  -80.115726    -123.00715458  1488.12335692 -1149.05344296 -2312.04036539\n",
      "   169.41344912 -1703.79947096 -2563.08335206 -1581.72967148    44.16591646]\n",
      "val: 6 comp: 7\n",
      "Done! [   90.51566652   155.69508286  -267.67567237   153.87582223  3286.9884875\n",
      "    58.09504181  2815.93652742  -813.14018199  3981.6703931     71.04324937]\n",
      "val: 7 comp: 5\n",
      "Done! [   83.69472138   126.13218046 -1402.68670113  1096.80830517  2419.69079043\n",
      "  -195.05734131  1775.94834839  2612.34246022  1544.11978881   -41.89554764]\n"
     ]
    }
   ],
   "source": [
    "ptron = PerceptronMultiClassifier()\n",
    "ptron.fit(train.values, y.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1,\n",
       "  1,\n",
       "  1,\n",
       "  7,\n",
       "  1,\n",
       "  1,\n",
       "  7,\n",
       "  1,\n",
       "  7,\n",
       "  1,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  1,\n",
       "  7,\n",
       "  7,\n",
       "  1,\n",
       "  7,\n",
       "  1,\n",
       "  7,\n",
       "  1,\n",
       "  7,\n",
       "  7,\n",
       "  1,\n",
       "  1,\n",
       "  7,\n",
       "  1,\n",
       "  1,\n",
       "  7,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  7,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  7,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " [2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2],\n",
       " [2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2],\n",
       " [7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  5,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  7,\n",
       "  5,\n",
       "  7,\n",
       "  7,\n",
       "  5,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  5,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7],\n",
       " [7,\n",
       "  7,\n",
       "  7,\n",
       "  6,\n",
       "  7,\n",
       "  6,\n",
       "  6,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  6,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  6,\n",
       "  7,\n",
       "  7,\n",
       "  6,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7],\n",
       " [7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  5,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  7,\n",
       "  5,\n",
       "  7,\n",
       "  7,\n",
       "  5,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  5,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7]]"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = ptron.predict(test.values)\n",
    "predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 2 6 2 1 2 1 7 1 5 5 5 1 2 6 1 2 2 7 1 7 7 2 1 2 1 3 7 1 2 2 7 3 2 2 1\n",
      " 1 2 2 2 3 1] and\n",
      "[1, 1, 1, 7, 1, 1, 7, 1, 7, 1, 7, 7, 7, 1, 7, 7, 1, 7, 1, 7, 1, 7, 7, 1, 1, 7, 1, 1, 7, 1, 1, 1, 7, 1, 1, 1, 1, 1, 1, 7, 1, 1, 1]\n",
      "0.46511627906976744\n",
      "[[14  0  0  0  0  0]\n",
      " [10  0  0  0  0  5]\n",
      " [ 3  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  3]\n",
      " [ 0  0  0  0  0  2]\n",
      " [ 0  0  0  0  0  6]]\n",
      "[1 1 2 6 2 1 2 1 7 1 5 5 5 1 2 6 1 2 2 7 1 7 7 2 1 2 1 3 7 1 2 2 7 3 2 2 1\n",
      " 1 2 2 2 3 1] and\n",
      "[2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "0.37209302325581395\n",
      "[[ 0 12  2  0  0  0]\n",
      " [ 0 15  0  0  0  0]\n",
      " [ 0  2  1  0  0  0]\n",
      " [ 0  3  0  0  0  0]\n",
      " [ 0  2  0  0  0  0]\n",
      " [ 0  6  0  0  0  0]]\n",
      "[1 1 2 6 2 1 2 1 7 1 5 5 5 1 2 6 1 2 2 7 1 7 7 2 1 2 1 3 7 1 2 2 7 3 2 2 1\n",
      " 1 2 2 2 3 1] and\n",
      "[2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "0.37209302325581395\n",
      "[[ 0 12  2  0  0  0]\n",
      " [ 0 15  0  0  0  0]\n",
      " [ 0  2  1  0  0  0]\n",
      " [ 0  3  0  0  0  0]\n",
      " [ 0  2  0  0  0  0]\n",
      " [ 0  6  0  0  0  0]]\n",
      "[1 1 2 6 2 1 2 1 7 1 5 5 5 1 2 6 1 2 2 7 1 7 7 2 1 2 1 3 7 1 2 2 7 3 2 2 1\n",
      " 1 2 2 2 3 1] and\n",
      "[7, 7, 7, 7, 7, 7, 5, 7, 7, 7, 5, 5, 5, 7, 5, 7, 7, 5, 7, 7, 7, 7, 7, 7, 7, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n",
      "0.20930232558139536\n",
      "[[ 0  0  0  0  0 14]\n",
      " [ 0  0  0  4  0 11]\n",
      " [ 0  0  0  0  0  3]\n",
      " [ 0  0  0  3  0  0]\n",
      " [ 0  0  0  0  0  2]\n",
      " [ 0  0  0  0  0  6]]\n",
      "[1 1 2 6 2 1 2 1 7 1 5 5 5 1 2 6 1 2 2 7 1 7 7 2 1 2 1 3 7 1 2 2 7 3 2 2 1\n",
      " 1 2 2 2 3 1] and\n",
      "[7, 7, 7, 6, 7, 6, 6, 7, 7, 7, 6, 7, 7, 7, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 6, 6, 6, 7, 7, 7, 7, 7, 7, 6, 7, 7, 6, 7, 7, 7, 7, 7, 7]\n",
      "0.18604651162790697\n",
      "[[ 0  0  0  0  5  9]\n",
      " [ 0  0  0  0  4 11]\n",
      " [ 0  0  0  0  1  2]\n",
      " [ 0  0  0  0  1  2]\n",
      " [ 0  0  0  0  2  0]\n",
      " [ 0  0  0  0  0  6]]\n",
      "[1 1 2 6 2 1 2 1 7 1 5 5 5 1 2 6 1 2 2 7 1 7 7 2 1 2 1 3 7 1 2 2 7 3 2 2 1\n",
      " 1 2 2 2 3 1] and\n",
      "[7, 7, 7, 7, 7, 7, 5, 7, 7, 7, 5, 5, 5, 7, 5, 7, 7, 5, 7, 7, 7, 7, 7, 7, 7, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n",
      "0.20930232558139536\n",
      "[[ 0  0  0  0  0 14]\n",
      " [ 0  0  0  4  0 11]\n",
      " [ 0  0  0  0  0  3]\n",
      " [ 0  0  0  3  0  0]\n",
      " [ 0  0  0  0  0  2]\n",
      " [ 0  0  0  0  0  6]]\n"
     ]
    }
   ],
   "source": [
    "for aSet in predictions:\n",
    "    \n",
    "    count = 0\n",
    "    for i in range(len(aSet)):\n",
    "        if aSet[i] == z.values[i]:\n",
    "            count += 1\n",
    "            \n",
    "    print(z.values,'and')\n",
    "    print(aSet)\n",
    "    print(count / len(aSet))\n",
    "    \n",
    "   \n",
    "    \n",
    "    print(confusion_matrix(z.values, aSet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hmm... that did not turn out the way I wanted it. Lets try a random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        RI     Na    Mg    Al     Si     K    Ca   Ba   Fe  Type\n",
       "0  1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.0  0.0     1\n",
       "1  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.0     1\n",
       "2  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.0     1\n",
       "3  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.0     1\n",
       "4  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.0     1"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glassData = glassData.drop(['Label'], axis = 1)\n",
    "glassData.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "elements = glassData[glassData.columns[:-1].tolist()] \n",
    "glassType = glassData['Type'] \n",
    "elements_train, elements_test, glassType_train, glassType_test = train_test_split(elements, glassType, train_size = .8 , random_state = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 7 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: 80.628409 (+/- 6.990165) performed in 0.924727 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzYAAAIICAYAAAC8SHsoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8oQNAABQ3v8DgoCMDZ+Q4VUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fab40b59dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import (FunctionTransformer, StandardScaler)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from time import time\n",
    "n_components = 5\n",
    "pipelines = []\n",
    "n_estimators = 200\n",
    "pipelines.append( ('Random Forest',Pipeline([('sc', StandardScaler()),('RF', RandomForestClassifier(random_state=8, n_estimators=n_estimators)) ]) ))\n",
    "\n",
    "results, names, times  = [], [] , []\n",
    "num_folds = 10\n",
    "scoring = 'accuracy'\n",
    "\n",
    "for name, model in pipelines:\n",
    "    start = time()\n",
    "    kfold = StratifiedKFold(n_splits=num_folds, random_state=8)\n",
    "    cv_results = cross_val_score(model, elements_train, glassType_train, cv=kfold, scoring = scoring,\n",
    "                                n_jobs=-1) \n",
    "    t_elapsed = time() - start\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    times.append(t_elapsed)\n",
    "    msg = \"%s: %f (+/- %f) performed in %f seconds\" % (name, 100*cv_results.mean(), \n",
    "                                                       100*cv_results.std(), t_elapsed)\n",
    "    print(msg)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(14,9))    \n",
    "ax = fig.add_subplot(1,1,1)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# it seems as though I was wrong about the dataset being linear... the random forest algorithm works much better than the one based on multi perceptron. That being said, it's preformance has a wide distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
